{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VC_metric_eval.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjH6biZa3ckkPbVk11iYDT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepaliVerma/personal_files/blob/main/VC_metric_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sGm-qas3ZS5"
      },
      "source": [
        "#https://github.com/yaoli/arctic-capgen-vid/blob/8a4ad9145006dcb625df8d68e97653f7ca4e53be/cocoeval.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdBgYom_vyj_",
        "outputId": "5c6310d1-e253-4bc4-bcf1-59b6d3051d62"
      },
      "source": [
        "!pip install pycocoevalcap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycocoevalcap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/f9/466f289f1628296b5e368940f89e3cfcfb066d15ddc02ff536dc532b1c93/pycocoevalcap-1.2-py3-none-any.whl (104.3MB)\n",
            "\u001b[K     |████████████████████████████████| 104.3MB 30kB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from pycocoevalcap) (2.0.2)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (57.0.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (0.29.23)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.15.0)\n",
            "Installing collected packages: pycocoevalcap\n",
            "Successfully installed pycocoevalcap-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0VjMBEEwBSk"
      },
      "source": [
        "import _pickle as cPickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is4C9IcTrJx8",
        "outputId": "25ebb626-f75c-4f8f-fe04-359bbf6e2806"
      },
      "source": [
        "from pycocoevalcap.bleu.bleu import Bleu\n",
        "from pycocoevalcap.rouge.rouge import Rouge\n",
        "from pycocoevalcap.cider.cider import Cider\n",
        "from pycocoevalcap.meteor.meteor import Meteor\n",
        "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
        "import os\n",
        "\n",
        "class COCOScorer(object):\n",
        "    def __init__(self):\n",
        "        print ('init COCO-EVAL scorer')\n",
        "            \n",
        "    def score(self, GT, RES, IDs):\n",
        "        self.eval = {}\n",
        "        self.imgToEval = {}\n",
        "        gts = {}\n",
        "        res = {}\n",
        "        for ID in IDs:\n",
        "            gts[ID] = GT[ID]\n",
        "            res[ID] = RES[ID]\n",
        "        print ('tokenization...')\n",
        "        tokenizer = PTBTokenizer()\n",
        "        gts  = tokenizer.tokenize(gts)\n",
        "        res = tokenizer.tokenize(res)\n",
        "\n",
        "        # =================================================\n",
        "        # Set up scorers\n",
        "        # =================================================\n",
        "        print('setting up scorers...')\n",
        "        scorers = [\n",
        "            (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
        "            (Meteor(),\"METEOR\"),\n",
        "            (Rouge(), \"ROUGE_L\"),\n",
        "            (Cider(), \"CIDEr\")\n",
        "        ]\n",
        "\n",
        "        # =================================================\n",
        "        # Compute scores\n",
        "        # =================================================\n",
        "        eval = {}\n",
        "        for scorer, method in scorers:\n",
        "            print('computing %s score...'%(scorer.method()))\n",
        "            score, scores = scorer.compute_score(gts, res)\n",
        "            if type(method) == list:\n",
        "                for sc, scs, m in zip(score, scores, method):\n",
        "                    self.setEval(sc, m)\n",
        "                    self.setImgToEvalImgs(scs, IDs, m)\n",
        "                    print(\"%s: %0.3f\"%(m, sc))\n",
        "            else:\n",
        "                self.setEval(score, method)\n",
        "                self.setImgToEvalImgs(scores, IDs, method)\n",
        "                print(\"%s: %0.3f\"%(method, score))\n",
        "                \n",
        "        for metric, score in self.eval.items():\n",
        "            print('%s: %.3f'%(metric, score))\n",
        "        return self.eval\n",
        "    \n",
        "    def setEval(self, score, method):\n",
        "        self.eval[method] = score\n",
        "\n",
        "    def setImgToEvalImgs(self, scores, imgIds, method):\n",
        "        for imgId, score in zip(imgIds, scores):\n",
        "            if not imgId in self.imgToEval:\n",
        "                self.imgToEval[imgId] = {}\n",
        "                self.imgToEval[imgId][\"image_id\"] = imgId\n",
        "            self.imgToEval[imgId][method] = score\n",
        "\n",
        "            \n",
        "def load_pkl(path):    \n",
        "    f = open(path, 'rb')\n",
        "    try:\n",
        "        rval = cPickle.load(f)\n",
        "    finally:\n",
        "        f.close()\n",
        "    return rval\n",
        "\n",
        "def score(ref, sample):\n",
        "    # ref and sample are both dict\n",
        "    scorers = [\n",
        "        (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
        "        (Meteor(),\"METEOR\"),\n",
        "        (Rouge(), \"ROUGE_L\"),\n",
        "        (Cider(), \"CIDEr\")\n",
        "    ]\n",
        "    final_scores = {}\n",
        "    for scorer, method in scorers:\n",
        "        print('computing %s score with COCO-EVAL...'%(scorer.method()))\n",
        "        score, scores = scorer.compute_score(ref, sample)\n",
        "        if type(score) == list:\n",
        "            for m, s in zip(method, score):\n",
        "                final_scores[m] = s\n",
        "        else:\n",
        "            final_scores[method] = score\n",
        "    return final_scores\n",
        "\n",
        "def test_cocoscorer():\n",
        "    '''gts = {\n",
        "        184321:[\n",
        "        {u'image_id': 184321, u'id': 352188, u'caption': u'A train traveling down-tracks next to lights.'},\n",
        "        {u'image_id': 184321, u'id': 356043, u'caption': u\"A blue and silver train next to train's station and trees.\"},\n",
        "        {u'image_id': 184321, u'id': 356382, u'caption': u'A blue train is next to a sidewalk on the rails.'},\n",
        "        {u'image_id': 184321, u'id': 361110, u'caption': u'A passenger train pulls into a train station.'},\n",
        "        {u'image_id': 184321, u'id': 362544, u'caption': u'A train coming down the tracks arriving at a station.'}],\n",
        "        81922: [\n",
        "        {u'image_id': 81922, u'id': 86779, u'caption': u'A large jetliner flying over a traffic filled street.'},\n",
        "        {u'image_id': 81922, u'id': 90172, u'caption': u'An airplane flies low in the sky over a city street. '},\n",
        "        {u'image_id': 81922, u'id': 91615, u'caption': u'An airplane flies over a street with many cars.'},\n",
        "        {u'image_id': 81922, u'id': 92689, u'caption': u'An airplane comes in to land over a road full of cars'},\n",
        "        {u'image_id': 81922, u'id': 823814, u'caption': u'The plane is flying over top of the cars'}]\n",
        "        }\n",
        "        \n",
        "    samples = {\n",
        "        184321: [{u'image_id': 184321, 'id': 111, u'caption': u'train traveling down a track in front of a road'}],\n",
        "        81922: [{u'image_id': 81922, 'id': 219, u'caption': u'plane is flying through the sky'}],\n",
        "        }\n",
        "    '''\n",
        "    gts = {\n",
        "        '184321':[\n",
        "        {u'image_id': '184321', u'cap_id': 0, u'caption': u'A train traveling down tracks next to lights.',\n",
        "         'tokenized': 'a train traveling down tracks next to lights'},\n",
        "        {u'image_id': '184321', u'cap_id': 1, u'caption': u'A train coming down the tracks arriving at a station.',\n",
        "         'tokenized': 'a train coming down the tracks arriving at a station'}],\n",
        "        '81922': [\n",
        "        {u'image_id': '81922', u'cap_id': 0, u'caption': u'A large jetliner flying over a traffic filled street.',\n",
        "         'tokenized': 'a large jetliner flying over a traffic filled street'},\n",
        "        {u'image_id': '81922', u'cap_id': 1, u'caption': u'The plane is flying over top of the cars',\n",
        "         'tokenized': 'the plan is flying over top of the cars'},]\n",
        "        }\n",
        "        \n",
        "    samples = {\n",
        "        '184321': [{u'image_id': '184321', u'caption': u'train traveling down a track in front of a road'}],\n",
        "        '81922': [{u'image_id': '81922', u'caption': u'plane is flying through the sky'}],\n",
        "        }\n",
        "    IDs = ['184321', '81922']\n",
        "    scorer = COCOScorer()\n",
        "    scorer.score(gts, samples, IDs)\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    test_cocoscorer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init COCO-EVAL scorer\n",
            "tokenization...\n",
            "setting up scorers...\n",
            "computing Bleu score...\n",
            "{'testlen': 16, 'reflen': 19, 'guess': [16, 14, 12, 10], 'correct': [9, 4, 2, 0]}\n",
            "ratio: 0.8421052631135734\n",
            "Bleu_1: 0.466\n",
            "Bleu_2: 0.332\n",
            "Bleu_3: 0.248\n",
            "Bleu_4: 0.000\n",
            "computing METEOR score...\n",
            "METEOR: 0.233\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.427\n",
            "computing CIDEr score...\n",
            "CIDEr: 1.290\n",
            "Bleu_1: 0.466\n",
            "Bleu_2: 0.332\n",
            "Bleu_3: 0.248\n",
            "Bleu_4: 0.000\n",
            "METEOR: 0.233\n",
            "ROUGE_L: 0.427\n",
            "CIDEr: 1.290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUj4cGZKvTdC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}